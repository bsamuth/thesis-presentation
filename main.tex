\documentclass[aspectratio=169, 22pt]{beamer}
\makeatletter
\def\input@path{{./sty/}}
\makeatother

\usetheme{greyc}
%Choose your language
\def\lang{english} %set it to english or french to have the logo in the good language

\usepackage{amsmath,amsfonts,amssymb,latexsym}
\usepackage{mathtools,bbm}
\usepackage[justification=centering]{caption}
\usepackage[justification=centering]{subcaption}
\usepackage[export]{adjustbox}

\graphicspath{{./img/},{./figs/}}

\captionsetup[figure]{labelformat=empty,justification=centering}

\DeclareMathOperator*{\argmin}{argmin}
\def\x{{\mathbf x}}
\def\L{{\cal L}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\title[Hybrid models for image generation]{Hybrid models for image generation}
\subtitle{}
\author[Benjamin Samuth]{Benjamin Samuth}
\institute[Normandie University]{Normandie Univ, UNICAEN, ENSICAEN, CNRS, GREYC, Caen, FRANCE}
\email{benjamin.samuth@unicaen.fr}
\web{}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

% ============================================
% ============================================
\section{Introduction}

\subsection{Context}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Evolution of Image Generation}
      \begin{itemize}
      \item Wide range of applications
      \item Usually for artistic uses
      \item Deep learning $\Rightarrow$ \alert{New paradigm}
      \end{itemize}
      
      \begin{figure}
        \captionsetup[subfigure]{labelformat=empty}
        \centering
        \begin{subfigure}[t]{0.19\linewidth}\centering
          \includegraphics[width=\linewidth]{texture.png}
          \caption{{\scriptsize Texture synthesis \newline {\tiny [Ashikhmin et al., 2001]}}}
        \end{subfigure}
        \begin{subfigure}[t]{0.19\linewidth}\centering
          \includegraphics[width=\linewidth]{patchmatch.png}
          \caption{{\footnotesize Editing \newline {\scriptsize [Barnes et al., 2009]}}}
        \end{subfigure}        
        \begin{subfigure}[t]{0.19\linewidth}\centering
          \includegraphics[width=\linewidth]{gatys}
          \caption{{\footnotesize Style transfer \newline {\scriptsize [Gatys et al., 2016]}}}
        \end{subfigure}
        \begin{subfigure}[t]{0.19\linewidth}\centering
          \includegraphics[width=\linewidth]{stylegan}
          \caption{{\footnotesize Face generation (\emph{StyleGAN}) \newline {\scriptsize [Karras et al., 2019]}}}
        \end{subfigure}        
        \begin{subfigure}[t]{0.19\linewidth}\centering
          \includegraphics[width=\linewidth]{stable-diffusion}
          \caption{{\footnotesize Text-to-image (Diffusion) \newline {\tiny [Rombach et al., 2022]}}}
        \end{subfigure}
      \end{figure}
\end{frame}


\begin{frame}{\secname~- \subsecname}
  \framesubtitle{The price of performance}
  \begin{figure}
    \begin{subfigure}[t]{0.24\linewidth}\centering
      \includegraphics[width=\linewidth]{gatys}
      \caption{{\emph{Neural style transfer}\newline[Gatys et al., 2016]\newline 15M parameters\newline 2 images}}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\linewidth}\centering
      \includegraphics[width=\linewidth]{stylegan}                
      \caption{{\emph{StyleGAN}\newline[Karras et al., 2019]\newline 30M parameters\newline 70,000 images}}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\linewidth}\centering
      \includegraphics[width=\linewidth]{esser}                      
      \caption{\emph{Taming transformers}\newline[Esser et al., 2021]\newline 800M parameters\newline 100,000 images}
    \end{subfigure}
    \begin{subfigure}[t]{0.24\linewidth}\centering
      \includegraphics[width=\linewidth]{stable-diffusion}
      \caption{\emph{Latent Diffusion}\newline[Rombach et al., 2022]\newline 1B parameters\newline 2B images}
    \end{subfigure}
  \end{figure}
  \begin{exampleblock}{}
    Quality, performance $\Rightarrow$ \textbf{More \alert{parameters}, more training \alert{data}}
  \end{exampleblock}
\end{frame}


\subsection{Challenges}
\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{customblock}{Scientific}
        \begin{itemize}
        \item Hardware requirements
        \item Reproductibility
        \end{itemize}
      \end{customblock}
      \pause
      \begin{block}{Ethic}
        \begin{itemize}
        \item Data security
        \item Copyright theft
        \end{itemize}
      \end{block}
    \end{column}
    \begin{column}{0.5\linewidth}
      \pause
      \begin{alertblock}{Society}
        \begin{itemize}
        \item Fake news
        \item Propaganda
        \end{itemize}
      \end{alertblock}
      \pause
      \begin{exampleblock}{Environment}
        \begin{itemize}
        \item Electricity consumption
        \end{itemize}
      \end{exampleblock}
    \end{column}
  \end{columns}
\end{frame}

\subsection{Lightweight models}
% \begin{frame}{\secname~- \subsecname}
%   \begin{exampleblock}{\centering Quels critères pour faire face à ces enjeux ?}
%     \begin{itemize}
%       \pause
%     \item Des modèles \alert{légers}
%       \pause
%     \item Des modèles \alert{explicables}
%     \end{itemize}
%     \pause
%     ... mais tout de même les plus performants possibles~!
%   \end{exampleblock}
% \end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Goals}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{customblock}{Lightweight models}
        \begin{itemize}
        \item \small Parameters
        \item \small Training data
        \item \small Operations
        \end{itemize}
      \end{customblock}
      \begin{alertblock}{Challenges}
        \begin{itemize}
        \item \small Quality/Diversity
        \item \small Range of action (ex: single image)
        \end{itemize}
      \end{alertblock}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \centering
        \begin{subfigure}{\linewidth}
          \centering
          \includegraphics[width=0.4\linewidth]{fastgan.png}
          \caption{\emph{Few-shot} generation (FastGAN) [Liu et al., 2020]}
        \end{subfigure}
        
        \begin{subfigure}{\linewidth}
          \centering
          \includegraphics[width=0.8\linewidth]{granot.png}
          \caption{\emph{GPNN} (\emph{``Drop the GAN''}) [Granot et al., 2022]}
        \end{subfigure}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}


\subsection{Explainable models}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Goals}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{block}{Modèles explicables}        
        \begin{itemize}
        \item \small Emerging topic
        \item \small Understand how and why
        \item \small State the capacity and limits
        \item \small Present proofs (bias, data security, ...)
        \end{itemize}
      \end{block}
      \begin{alertblock}{Limits and Challenges}
        \begin{itemize}
        \item \small \emph{Post-hoc}
        \item \small Nothing for generative models
        \end{itemize}
      \end{alertblock}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=0.5\linewidth]{jeanneret}
        \caption{{Counterfactual explanations [Jeanneret et al., 2023]}}
      \end{figure}
    \end{column}
  \end{columns}    
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \begin{customblock}{\centering Main problematic}
    \centering
    Can we balance quality (photorealism) with lightweightness and explainability of models?
  \end{customblock}
\end{frame}

\subsection{``Hybrid'' models}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Motivation}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{block}{Deep models}
        \begin{itemize}
        \item \small Photorealism (quality)
        \item \small Diverse generation
        \item \small Non-explainable and complex
        \end{itemize}
      \end{block}      
    \end{column}

    \pause
    \begin{column}{0.5\linewidth}
      \begin{customblock}{Lightweight models}
        \begin{itemize}
        \item \small Lightweight, explainable
        \item \small Compromise on quality/diversity
        \item \small Smaller range of applications
        \end{itemize}
      \end{customblock}      
    \end{column}    
  \end{columns}

  \vfill
  \pause
  \begin{exampleblock}{\centering Hybrid methods for image generation}
    \centering
    \alert{Idea}: Combine lightweight methods and deep models in order to preserve the best of both worlds
  \end{exampleblock}
  \begin{itemize}
    \centering
    \item A concept yet to be explored...!
  \end{itemize}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Plan}
  \begin{columns}
    \begin{column}{0.3\linewidth}
      \begin{itemize}
        \centering
        \item \small 1. \alert{Qualitatively} highlight their relevance in artistic style transfer
      \end{itemize}
    \end{column}
    \begin{column}{0.3\linewidth}
      \begin{itemize}
        \centering
      \item \small 2. Show their \alert{efficiency} for few-shot face generation
      \end{itemize}      
    \end{column}
    \begin{column}{0.3\linewidth}
      \begin{itemize}
        \centering
      \item \small 3. Propose ways to \alert{generalize} them on diverse dataset
      \end{itemize}      
    \end{column}
  \end{columns}
\end{frame}


% ============================================
% ============================================
\section{Preliminary concepts}
% Justifier leur utilisation
\begin{frame}
  \begin{beamercolorbox}[sep=15pt,center,shadow=true,rounded=true]{title}
    \LARGE\bfseries \secname
  \end{beamercolorbox}
\end{frame}

\subsection{Encoders}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Principe}
  \begin{columns}
    \begin{column}{0.4\linewidth}
      \begin{block}{Encoders}
        \begin{itemize}
        \item Supervised training (classification)
        \item Use case: features, metrics
        \end{itemize}
      \end{block}
    \end{column}
    \begin{column}{0.6\linewidth}
      \begin{figure}
        \centering
        \includegraphics[height=0.6\textheight]{vgg16.png}
        \caption{\emph{VGG-16} [Simonyan et al., 2014]}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}

\subsection{Auto-encoders}
\begin{frame}{\secname~- \subsecname}
  \begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{4.png}
    \caption{Scheme of an auto-encodeur}
    \begin{block}{Reconstruction}
      \centering
      \begin{itemize}        
      \item Optimisation of a reconstruction objective
      \end{itemize}
      $\underset{E,D}{\min}\ \underset{x \sim p(x)}{\mathbb{E}}\left[\mathcal{L}_{\text{rec}}(x,D(E(x)))\right]$
      \begin{itemize}
      \item \alert{Latent} and compact representation
      \end{itemize}

    \end{block}
  \end{figure}
  
\end{frame}

\subsection{Patch-based methods}
% Alléger déf
% parler de patchmatch
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Definition}
  \begin{columns}
    \begin{column}{0.6\linewidth}
      \begin{figure}
        \centering
        \includegraphics[valign=m,width=0.55\linewidth]{2.png}
        \includegraphics[valign=m,width=0.4\linewidth]{3.png}
      \end{figure}
    \end{column}
    
    \begin{column}{0.4\linewidth}
      \begin{itemize}
      \item Texture synthesis [Efros et Leung, 1999], [Ashikhmin et al., 2001]
        \vspace{1em}
      \item Patch nearest neighbor search
      \item \emph{PatchMatch} [Barnes et al., 2009]
      \end{itemize}
      % \emph{Image} : $x \in \mathbb{R}^{W \times H \times C}$
      % \begin{itemize}
      %   \footnotesize 
      % \item de taille $W \times H$
      % \item à $C$ canaux de couleurs
      % \end{itemize}
      
      % \vfill
      % \emph{Extraction de patch} : $P$
      % \begin{itemize}
      %   \footnotesize 
      % \item Opérateur linéaire
      % \item Extrait des patchs de taille $\sigma \times \sigma$
      % \item Gère les effets de bords
      % \end{itemize}

      % \vfill
      % \emph{Position} : $i \in \Omega$
      % \begin{itemize}
      %   \footnotesize 
      % \item $\Omega = \{1,\dots,W\}\times\{1,\dots,H\}$
      % \end{itemize}

      % \vfill
      % \emph{Patch} : $P(x,i) \in \mathbb{R}^{\sigma \times \sigma \times C}$
      % \begin{itemize}
      %   \footnotesize 
      %   \item $\forall (u,v) \in \{0,\dots,\sigma-1\}^2,\ P(x,i)_{u, v, \cdot} =
      %     x_{i+(u,v)}$
      %   \item par simplicité, sous forme vectorisée (\emph{ie.} $\mathbb{R}^{\sigma^2 C}$)
      % \end{itemize}     
    \end{column}
  \end{columns}  
\end{frame}

% Warping
% Méthode de génération pour les méthodes à patchs
% Notation R o W
\begin{frame}{\secname~- \subsecname} 
  \framesubtitle{Assignment, Warping}
  \begin{columns}
    \begin{column}{0.55\linewidth}
      \begin{exampleblock}{Assignment map}
        \begin{itemize}
        \item Aggregation/\emph{warping} of patches
        \item (Re)construct an image from an \alert{assignment of coordinates}
        \item Explainable generation
        \end{itemize}
      \end{exampleblock}
    \end{column}
    \begin{column}{0.45\linewidth}
      \begin{figure}
        \centering
        \includegraphics[height=0.6\textheight]{nnf.png}
        \caption{(a) Image $x = x \circ W_b$ \quad(b) Identity $W_b$
          \\ (c) Image $y = x \circ W_d$ \quad(d) Map $W_d$}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}


% ============================================
% ============================================
\section{Style transfer with constrained patches}
\begin{frame}
  \vfill
  \begin{beamercolorbox}[sep=15pt,center,shadow=true,rounded=true]{title}
    \LARGE\bfseries Contribution 1.\\ \secname
  \end{beamercolorbox}
  \vfill
  \begin{itemize}
  \item \footnotesize Benjamin Samuth, David
    Tschumperlé, and Julien Rabin (2022). ``A Patch-Based Approach for
    Artistic Style Transfer Via Constrained Multi-Scale Image
    Matching'', \emph{2022 IEEE International Conference on Image
      Processing (ICIP)}.
  \item \footnotesize Benjamin Samuth, David Tschumperlé, and Julien Rabin (2022).
    ``Transfert de style d’images par mise en correspondance multi-échelle et
    contrainte de patchs'', \emph{GRETSI 2022}.
  \end{itemize}
\end{frame}

\subsection{Context}
% Image I, R, noter J
\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.4\linewidth}
      \begin{figure}
        \centering
        \begin{subfigure}{0.45\linewidth}\centering
          \includegraphics[width=0.6\linewidth]{balloon/starry_night_s}
          \caption{Style $R$}
        \end{subfigure}
        \begin{subfigure}{0.45\linewidth}\centering        
          \includegraphics[width=0.6\linewidth]{balloon/balloon_s}
          \caption{Content $I$}
        \end{subfigure}

        \begin{subfigure}{0.8\linewidth}\centering
          \includegraphics[width=0.9\linewidth]{balloon/gatys.png}
          \caption{Synthesis $J$}
        \end{subfigure}
      \end{figure}
    \end{column}
    \begin{column}{0.6\linewidth}
      \begin{customblock}{Definition}
        \begin{itemize}
        \item \small Style : \alert{aesthetical features}
        \item \small Style transfer : style from a \alert{reference} image $R$ onto
          a \alert{content} image $I$ (\emph{Input})
        \item \small Challenge : Modelize a style
        \end{itemize}    
      \end{customblock}
      \begin{block}{\emph{Neural style transfer} [Gatys et al., 2016]}
        \begin{itemize}
        \item \small Optimization over pixels on
          \emph{VGG-16} \emph{features}  [Simonyan et al., 2014]
        \item \small \alert{Long} task (5-15 min./image on GPU)
        \end{itemize}
      \end{block}
    \end{column}
  \end{columns}
\end{frame}

\subsection{Method}
\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.4\linewidth}
      \begin{figure}
        \centering
        \begin{subfigure}{0.45\linewidth}\centering
          \includegraphics[width=0.6\linewidth]{balloon/starry_night_s}
          \caption{Style $R$}
        \end{subfigure}
        \begin{subfigure}{0.45\linewidth}\centering        
          \includegraphics[width=0.6\linewidth]{balloon/balloon_s}
          \caption{Content $I$}
        \end{subfigure}

        \begin{subfigure}{0.8\linewidth}\centering
          \includegraphics[width=0.9\linewidth]{balloon/ours.png}
          \caption{Synthesis $J$}
        \end{subfigure}
      \end{figure}
    \end{column}
    \begin{column}{0.6\linewidth}
      \begin{exampleblock}{Our method}
        \begin{itemize}
        \item Patch-based method
        \item Multi-scale
        \item Coarse to fine ($k=N..0$)
          \vspace{1em}
          \pause
        \item \alert{Occurence constraint}
        \item \alert{Experiments on patch metrics}
        \end{itemize}
      \end{exampleblock}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{5.pdf}
    \caption{Scheme of the style transfer at a scale $k$.}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{5_1}
    \caption{Scheme of the style transfer at a scale $k$.}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{5_2}
    \caption{Scheme of the style transfer at a scale $k$.}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{5_3}
    \caption{Scheme of the style transfer at a scale $k$.}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{5_4}
    \caption{Scheme of the style transfer at a scale $k$.}
  \end{figure}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Upscaling}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{itemize}
      \item $W_k$~: nearest neighbor mapping from $R_k$ to $J_k$.
      \item $W_k$ contains \alert{coordinates}
      \item Upscaling ratio $r > 1$
      \end{itemize}
      \begin{figure}
        \includegraphics[width=0.8\linewidth]{5_me.png}
      \end{figure}

    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{block}{Upscaling}
        \centering
        $W\!\!\uparrow^r(p) = \floor*{rW\left(\floor*{\frac{p}{r}}\right) + p - r\floor*{\frac{p}{r}}}$
      \end{block}
      \vspace{1em}
      \begin{exampleblock}{Pros}
        \begin{itemize}
        \item Immediate
        \item No quality loss
        \end{itemize}
      \end{exampleblock}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Occurrence penalty}
  \begin{columns}
    \begin{column}{0.5\linewidth}
        \begin{itemize}
        \item Nearest neighbor search is \emph{too} efficient
        \item Share the usage of patches more evenly
        \end{itemize}

      \begin{block}{Penalized patch distance}
        \centering
        \small
        $W_k^* \in \argmin_{W \in F}\ \sum_{p \in \Omega} \frac{D_k(p)}{Var(D_k)} - \lambda_W \circ W(p)$
        
        $\text{avec} \quad D_k(p) = ||\tilde{J}_k(p) - R_k \circ W(p)||^2$
      \end{block}
      \begin{itemize}
      \item $\lambda_W \circ W(p) < 0$~: Patch $p$ is penalized
      \item $\lambda_W \circ W(p) > 0$~: Patch $p$ is favored
      \end{itemize}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{6.png}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Occurrence penalty}
  \begin{columns}
    \begin{column}{0.5\linewidth}      
      \begin{block}{Penalty score update}
        \small
        \begin{center}
          $\lambda_W(y) \leftarrow \lambda_W(y) + \delta \partial_y \lambda_W(y) $
          
          $\partial_y\lambda_W(y) = \frac{\lvert\left\{p\ |\ y =
              W(p)\right\}\rvert}{\lvert\Omega_I\rvert} -
          \frac{\nu(y)}{\lvert\Omega_R\rvert}$
        \end{center}
        
        \begin{itemize}
        \item Initialized to 0 for each $y \in \Omega_R$.
        \item Inspired by optimal transport
        \item Applied during different iterations of \emph{PatchMatch} [Barnes et al., 2009]
        \end{itemize}
      \end{block}    
    \end{column}
    
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{6.png}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}

\subsection{Results}
\begin{frame}{\secname~- \subsecname}
  \begin{figure}
    \begin{subfigure}{0.47\linewidth}
      \includegraphics[width=\linewidth]{balloon/ours.png}
      \caption{\textbf{Ours} ($\Phi$ : RGB \& Gradients)}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{balloon/balloon_s.png}
        \caption{Content}
      \end{subfigure}
      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{balloon/starry_night_s.jpg}
        \caption{Style}
      \end{subfigure}

      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{balloon/gatys.png}
        \caption{\scriptsize [Gatys et al., 2016]}
      \end{subfigure}
      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{balloon/liu.png}
        \caption{[Liu et al., 2021]}
      \end{subfigure}
    \end{subfigure}
  \end{figure}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \begin{figure}
    \begin{subfigure}{0.47\linewidth}
      \includegraphics[width=\linewidth]{tuebingen/ours.png}
      \caption{\textbf{Ours} ($\Phi$ : \emph{VGG-16}, relu\_1\_1)}
    \end{subfigure}
    \begin{subfigure}{0.45\linewidth}
      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{tuebingen/tuebingen_s.jpg}
        \caption{Content}
      \end{subfigure}
      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{tuebingen/abstract_s}
        \caption{Style}
      \end{subfigure}

      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{tuebingen/gatys.png}
        \caption{\scriptsize[Gatys et al., 2016]}
      \end{subfigure}
      \begin{subfigure}{0.45\linewidth}
        \includegraphics[width=\linewidth]{tuebingen/liu.png}
        \caption{[Liu et al., 2021]}
      \end{subfigure}
    \end{subfigure}
  \end{figure}
\end{frame}


\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.52\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=0.9\linewidth]{7.png}
      \end{figure}
    \end{column}
    \begin{column}{0.48\linewidth}
      \begin{block}{Relevance of metrics}
        \begin{itemize}
        \item \emph{``Patch-features''} $\Phi$
        \item Experiment: transfer over an stylized image
        \item Each $\Phi$ captures something different
        \end{itemize}
      \end{block}
    \end{column}
  \end{columns}
\end{frame}


% ============================================
% ============================================
\section{Latent patches for image generation}
\begin{frame}
  \vfill
  \begin{beamercolorbox}[sep=15pt,center,shadow=true,rounded=true]{title}
    \LARGE\bfseries Contribution 2.\\ \secname
  \end{beamercolorbox}
  \vfill
  \begin{itemize}
  \item \footnotesize Benjamin Samuth, Julien Rabin, David Tschumperlé, and
    Frédéric Jurie (2023). ``LatentPatch: A Non-Parametric Approach for
    Face Generation and Editing'', \emph{2023 IEEE International
      Conference on Image Processing (ICIP)}.
  \item \footnotesize Benjamin Samuth, Julien Rabin, David Tschumperlé, and
    Frédéric Jurie (2023). ``LATENTPATCH : Une approche non-paramétrique
    pour la génération et l’édition de visages'', \emph{GRETSI 2023}.
  \item \footnotesize Benjamin Samuth, Julien Rabin, David Tschumperlé, and Frédéric Jurie
    (2024). ``A Non-Parametric Latent Model for Face Generation'', \emph{SSRN 4772632}.
  \end{itemize}
\end{frame}

\subsection{Motivation}
% \begin{frame}{\secname~- \subsecname}
%   \framesubtitle{Génération \emph{``few-shot''}}
%   \begin{itemize}
%   \item Génération avec peu de données
%   \item Entre 10 et 1000 échantillons
%   \item Problème difficile : instabilité ou mémorisation
%   \end{itemize}
%   \begin{customblock}{}
%     \centering
%     Certaines méthodes de l'état de l'art (\emph{transformers},
%     diffusion) sont \alert{inapplicables} telles quelles dans ces
%     configurations !
%   \end{customblock}
%   \pause
%   \begin{itemize}
%   \item Solutions : Architectures, augmentation de données, transfert de connaissances, ...
%   \item \alert{Inconvénient} : phase d'apprentissage longue malgré le peu de données ($\sim$2h)
%   \end{itemize}  
% \end{frame}
\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.3\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{25.png}
      \end{figure}
    \end{column}
    \begin{column}{0.7\linewidth}
      \begin{itemize}
      \item Method extended for generation
      \item Multiple images
      \item Realigned faces $\rightarrow$ Aligned patches
        \vspace{1em}
      \item Need of \alert{regularization}
      \end{itemize}
    \end{column}
  \end{columns}
\end{frame}

\subsection{\emph{VQGAN}}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{``Taming transformers'' [Esser et al., 2021]}
  \begin{columns}
    \begin{column}{0.2\linewidth}
      \begin{itemize}
      \item \small Auto-encoder
      \item \small Adversarial
      \item \small Quantified
      \item \small Spatial
        \vspace{1em}
      \item \small Generation with a \emph{Transformer}
      \end{itemize}
    \end{column}
    \begin{column}{0.8\linewidth}
      \begin{figure}
        \includegraphics[width=\linewidth]{10.png}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Properties}
  \begin{figure}
    \includegraphics[width=0.7\linewidth]{16.png}
  \end{figure}
  \begin{itemize}
  \item Photorealistic \alert{seamless blending}
  \item \alert{Harmonize} colors and textures
\end{itemize}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Is the decoder a generator?}
  \begin{figure}
    \includegraphics[width=0.6\linewidth]{15.png}
  \end{figure}
  \begin{itemize}
  \item The decoder \alert{is not} a generator by itself.
  \end{itemize}
\end{frame}


\subsection{Method}
\begin{frame}{\secname~- \subsecname}
  \begin{figure}
    \includegraphics[width=\linewidth]{11.pdf}
  \end{figure}
  \begin{itemize}
  \item $E, D$ : VQGAN pre-trained over FFHQ
  \item $\mathcal{X}$ : Limited \emph{dataset}
  \item $R$ : Dimension reduction with an PCA over the channels
  \item $G$ : \alert{Latent representation generator with a patch-based method}
  \end{itemize}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Auto-regressive sequential generation}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{12.pdf}
  \end{figure}
\end{frame}

\subsection{Experiments}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Results}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \includegraphics[width=\linewidth]{13a}
        \includegraphics[width=\linewidth]{13b}
      \end{figure}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \includegraphics[width=\linewidth]{14a}
        \includegraphics[width=\linewidth]{14b}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Explainable by design}
  \begin{columns}
    \begin{column}{0.4\linewidth}
      \begin{itemize}
      \item Relation between \alert{source} and \alert{generation} is immediate
      \end{itemize}
    \end{column}
    \begin{column}{0.6\linewidth}
      \begin{figure}
        \includegraphics[width=\linewidth]{17.png}
      \end{figure}  
    \end{column}
  \end{columns}  
\end{frame}

\subsection{Evaluation}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Qualitative comparison}
  \begin{columns}
    \begin{column}{0.75\linewidth}
      \begin{figure}
        \includegraphics[width=\linewidth]{18.png}
      \end{figure}
    \end{column}
    \begin{column}{0.25\linewidth}
      \begin{itemize}
      \item Comparaison avec \emph{FastGAN}
      \item \emph{LatentPatch} est bien + varié
      \end{itemize}
    \end{column}
  \end{columns}  
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Quantitative comparison - FID}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{fid-vs-subset.pdf}
  \end{figure}
\end{frame}

\subsection{Generalization}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Attempts}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{latentpatch_full_sources.png}
        \includegraphics[width=\linewidth]{latentpatch_full.png}
      \end{figure}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{exampleblock}{\emph{LatentPatch}}
        \begin{itemize}
        \item Works well in \emph{few-shot} : faces perceptually close
        \end{itemize}
      \end{exampleblock}
      \begin{alertblock}{Generalized \emph{LatentPatch}}
        \begin{itemize}
        \item Weak to diverse samples
        \item Lack of spatial coherency overall
        \end{itemize}
      \end{alertblock}
    \end{column}
  \end{columns}
\end{frame}

% ============================================
% ============================================
\section{Latent Gaussian mixture models}
% INtroduire le problème
% Cohérence spatiale
% Modèle gaussien pour capturrer

% Motiver par faible rang sampling
\begin{frame}
  \vfill
  \begin{beamercolorbox}[sep=15pt,center,shadow=true,rounded=true]{title}
    \LARGE\bfseries Contribution 3. \\ \secname
  \end{beamercolorbox}
  \vfill
  \begin{itemize}
    \item \footnotesize Benjamin Samuth, Julien Rabin, Frédéric Jurie, and David
      Tschumperlé (2024). ``A Low Rank Gaussian Mixture Latent Model for
      Face Generation'', \emph{International Conference on Pattern
        Recognition}.
  \end{itemize}
\end{frame}

\subsection{Motivation}
\begin{frame}{\secname~- \subsecname}
  \begin{figure}\centering
    \begin{subfigure}{0.3\linewidth}\centering
      \includegraphics[width=0.8\linewidth]{random_noise_q}
      \caption{White latent noise}
    \end{subfigure}
    \begin{subfigure}{0.3\linewidth}\centering
      \includegraphics[width=0.8\linewidth]{random_lr-gmm}
      \caption{Correlated noise latent}
    \end{subfigure}
  \end{figure}
  \begin{itemize}\centering
  \item \alert{Idea}: Constrain the \alert{spatial correlation} 
  \end{itemize}
  \begin{exampleblock}{Gaussian Mixture Models (\emph{GMM})}
    \begin{itemize}
    \item Modelize the covariance of the data
    \item Handle diverse samples
    \end{itemize}
  \end{exampleblock}  
\end{frame}

\subsection{Method}
\begin{frame}{\secname~- \subsecname}
  \begin{figure}
    \includegraphics[width=0.9\linewidth]{lrgmm.pdf}
  \end{figure}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{exampleblock}{Principe}
        \begin{itemize}
        \item \small Learn a \emph{GMM} over the latent representation
        \item \small Sample the \emph{GMM} at low rank as initialization
        \end{itemize}
      \end{exampleblock}
    \end{column}
    \begin{column}{0.5\linewidth}
        \begin{exampleblock}{}
        \begin{itemize}
        \item \small Project each latent patch to its NN
        \item \small Decode
        \end{itemize}
      \end{exampleblock}
    \end{column}
  \end{columns}
  
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Low rank sampling} 
  \begin{figure}
    \includegraphics[width=0.9\linewidth]{ablation_dk.png}
  \end{figure}  
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Refining through NN step}
  \begin{figure}
    \includegraphics[width=0.9\linewidth]{ablation_nn.png}
  \end{figure}    
\end{frame}

\subsection{Résultats}
\begin{frame}{\secname~- \subsecname}
  \framesubtitle{Qualitative comparisons}
  \begin{figure}
    \includegraphics[width=\linewidth]{comp_img}
  \end{figure}
\end{frame}

% ============================================
% ============================================
\section{Conclusion and Perspectives}
\begin{frame}
  \begin{beamercolorbox}[sep=15pt,center,shadow=true,rounded=true]{title}
    \LARGE\bfseries \secname
  \end{beamercolorbox}
\end{frame}

\subsection{Summary}
\begin{frame}{\secname~- \subsecname}
  \begin{customblock}{Quality, lightweightness, explainability}
    \begin{itemize}
    \item Problem: the growing of models
    \item Lightweightness and Explainability are potential answers
    \item Hybrid models can answer to these criterion
    \end{itemize}
  \end{customblock}

  \pause
  \begin{exampleblock}{Relevance of hybrid models}
    \begin{itemize}  
    \item 1. Deep representations are still relevant when combined with lightweight models
    \item 2. The compromise quality/computation time is at our advantage
    \item 3. Generalization to varied samples is possible
    \end{itemize}
  \end{exampleblock}
\end{frame}

\subsection{Perspectives}
\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=1\linewidth]{J_W_10.png}
      \end{figure}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{block}{Perspective 1 – Reduce the dependency on deep models}
        \begin{itemize}
        \item \alert{Limit}: Depedency on \emph{VQGAN}
        \item Interesting properties: harmonization, textured aggregation

        \item \alert{Idea}: Learn lightweight neural networks to encapsulate these properties
        \item Non-parametric approach?
        \end{itemize}

      \end{block}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{\secname~- \subsecname}
  \begin{columns}
    \begin{column}{0.6\linewidth}
      \begin{block}{Perspective 2 – Expand the capacity of the model}
        \begin{itemize}
        \item \alert{Limit}: Generation of aligned faces only
        \item What about other modalities?

        \item Tests on generic auto-encoders and non-aligned faces were inconclusive
        \item \alert{Idea}: Delegate the initialization to a neural
          network and refine with patches
        \end{itemize}
      \end{block}
    \end{column}
    \begin{column}{0.4\linewidth}
      \begin{figure}
        \centering
        \includegraphics[width=\linewidth]{24.png}
      \end{figure}
    \end{column}
  \end{columns}
\end{frame}


% the final page
\makethanks

\section{Suppléments}
\begin{frame}[noframenumbering]
  \begin{beamercolorbox}[sep=15pt,center,shadow=true,rounded=true]{title}
    \LARGE\bfseries \secname
  \end{beamercolorbox}
\end{frame}


\subsection{LatentPatch}
\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Biais de performance}
  \begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{19.pdf}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Comparaison quantitative - Precision}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{20.pdf}
    \caption{\small Calculé avec \emph{Improved Precision/Recall} [Kynkäänniemi et al., 2019]}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Comparaison quantitative - Rappel}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{21.pdf}
    \caption{\small Calculé avec \emph{Improved Precision/Recall} [Kynkäänniemi et al., 2019]}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Comparaison quantitative - Erreur perceptuelle moyenne}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{avg-nn-lpips.pdf}
    \caption{\small Calculé avec \emph{LPIPS} [Zhang et al., 2018]}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Coût computationnel}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{22.png}
  \end{figure}
  \begin{itemize}
  \item En échange d'un coût en paramètres raisonnable, notre méthode
    \emph{LatentPatch} peut se passer d'entraînement pour des performances
    similaires à \emph{FastGAN}.
  \end{itemize}
\end{frame}

\subsection{GMM latent}
\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Comparaisons quantitative}
  \begin{figure}
    \includegraphics[width=0.9\linewidth]{comp_tab}
  \end{figure}
  \scriptsize (1) [Esser et al., 2021] ; (2) [Liu et al., 2020]
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Carte d'affectation}
  \begin{figure}
    \includegraphics[width=0.8\linewidth]{teaser_0}
  \end{figure}
\end{frame}

\begin{frame}[noframenumbering]{\secname~- \subsecname}
  \framesubtitle{Clusters, centroïdes}
  \begin{figure}
    \includegraphics[width=\linewidth]{centroids}    
  \end{figure}
  \begin{itemize}
  \item Échantillonnage : $d_k = \floor*{\lambda \pi_k d_0}$
  \item $\lambda$ : Température
  \item $\pi_k$ : Amplitude du cluster $k$
  \item $d_0$ : Dimension totale (2048)
  \end{itemize}
\end{frame}

\end{document}
